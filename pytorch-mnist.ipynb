{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task\n",
    "Our task is simple, recognize handwritten digits. We will use MNIST dataset for this tutorial.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary library\n",
    "In this tutorial, we are going to use pytorch, the cutting-edge deep learning framework to complete our task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to dataset/MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:05<00:00, 1.66MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting dataset/MNIST\\raw\\train-images-idx3-ubyte.gz to dataset/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to dataset/MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 117kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting dataset/MNIST\\raw\\train-labels-idx1-ubyte.gz to dataset/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to dataset/MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.10MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting dataset/MNIST\\raw\\t10k-images-idx3-ubyte.gz to dataset/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to dataset/MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 4.54MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting dataset/MNIST\\raw\\t10k-labels-idx1-ubyte.gz to dataset/MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Create dataloader, in PyTorch, we feed the trainer data with use of dataloader\n",
    "## We create dataloader with dataset from torchvision, \n",
    "## and we dont have to download it seperately, all automatically done\n",
    "\n",
    "# Define batch size, batch size is how much data you feed for training in one iteration\n",
    "batch_size_train = 64 # We use a small batch size here for training\n",
    "batch_size_test = 1024 #\n",
    "\n",
    "# define how image transformed\n",
    "image_transform = torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])\n",
    "#image datasets\n",
    "train_dataset = torchvision.datasets.MNIST('dataset/', \n",
    "                                           train=True, \n",
    "                                           download=True,\n",
    "                                           transform=image_transform)\n",
    "test_dataset = torchvision.datasets.MNIST('dataset/', \n",
    "                                          train=False, \n",
    "                                          download=True,\n",
    "                                          transform=image_transform)\n",
    "#data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size=batch_size_train, \n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                          batch_size=batch_size_test, \n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: tensor(7)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import library\n",
    "import matplotlib.pyplot as plt\n",
    "# We can check the dataloader\n",
    "_, (example_datas, labels) = next(enumerate(test_loader))\n",
    "sample = example_datas[0][0]\n",
    "# show the data\n",
    "plt.imshow(sample, cmap='gray', interpolation='none')\n",
    "print(\"Label: \"+ str(labels[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now we can start to build our CNN model\n",
    "## We first import the pytorch nn module and optimizer\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "## Then define the model class\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        #input channel 1, output channel 10\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5, stride=1)\n",
    "        #input channel 10, output channel 20\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5, stride=1)\n",
    "        #dropout layer\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        #fully connected layer\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv2_drop(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(x)\n",
    "        x = x.view(-1, 320)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create model and optimizer\n",
    "learning_rate = 0.005\n",
    "momentum = 0.95\n",
    "device = \"cpu\"\n",
    "model = CNN().to(device) #using cpu here\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "##define train function\n",
    "def train(model, device, train_loader, optimizer, epoch, log_interval=10000):\n",
    "    model.train()\n",
    "    tk0 = tqdm(train_loader, total=int(len(train_loader)))\n",
    "    counter = 0\n",
    "    for batch_idx, (data, target) in enumerate(tk0):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        counter += 1\n",
    "        tk0.set_postfix(loss=(loss.item()*data.size(0) / (counter * train_loader.batch_size)))\n",
    "##define test function\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_3244\\1895196525.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  tk0 = tqdm(train_loader, total=int(len(train_loader)))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26c672ee53cb42d6825c4dc8bf62fa40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_3244\\4020281764.py:32: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.1932, Accuracy: 9452/10000 (95%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa714c10fe74470bb9ace22bab32df78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.1319, Accuracy: 9606/10000 (96%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2e523131416418f904d3a806b0b9c0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.1057, Accuracy: 9695/10000 (97%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 3\n",
    "for epoch in range(1, num_epoch + 1):\n",
    "        train(model, device, train_loader, optimizer, epoch)\n",
    "        test(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 10, 24, 24]             260\n",
      "            Conv2d-2             [-1, 20, 8, 8]           5,020\n",
      "         Dropout2d-3             [-1, 20, 8, 8]               0\n",
      "            Linear-4                   [-1, 50]          16,050\n",
      "            Linear-5                   [-1, 10]             510\n",
      "================================================================\n",
      "Total params: 21,840\n",
      "Trainable params: 21,840\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.06\n",
      "Params size (MB): 0.08\n",
      "Estimated Total Size (MB): 0.15\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_3244\\4020281764.py:32: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, (1, 28, 28))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "58cd16b22a53e8f225f4346339c6fbc90226716455e73ccb384283f30efeb411"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
